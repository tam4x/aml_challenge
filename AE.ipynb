{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aab56e3b",
      "metadata": {
        "id": "aab56e3b"
      },
      "source": [
        "#### File to test out Autoencoder and VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73d038d7",
      "metadata": {
        "id": "73d038d7",
        "outputId": "cf50d1a8-f760-4a9c-a3fe-54a83200035d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'challenge'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 98 (delta 39), reused 72 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (98/98), 21.03 MiB | 20.27 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "--2025-11-12 15:51:45--  https://raw.githubusercontent.com/tam4x/aml_challenge/refs/heads/main/preprocess_data.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8066 (7.9K) [text/plain]\n",
            "Saving to: ‘preprocess_data.py’\n",
            "\n",
            "preprocess_data.py  100%[===================>]   7.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-12 15:51:45 (121 MB/s) - ‘preprocess_data.py’ saved [8066/8066]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!mkdir data\n",
        "#!gdown 1CVAQDuPOiwm8h9LJ8a_oOs6zOWS6EgkB\n",
        "#!gdown 1ykZ9fjTxUwdiEwqagoYZiMcD5aG-7rHe\n",
        "#!unzip -o test.zip -d data\n",
        "#!unzip -o train.zip -d data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/Mamiglia/challenge.git\n",
        "!wget https://raw.githubusercontent.com/tam4x/aml_challenge/refs/heads/main/preprocess_data.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5d9d7269",
      "metadata": {
        "id": "5d9d7269"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "from challenge.src.common import load_data, prepare_train_data, generate_submission"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75061d07",
      "metadata": {
        "id": "75061d07"
      },
      "source": [
        "#### Create Neural Network Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58623330",
      "metadata": {
        "id": "58623330"
      },
      "source": [
        "##### Normal Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "09226d1b",
      "metadata": {
        "id": "09226d1b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TranslatorAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, output_dim, hidden_dim=512, n_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dim\n",
        "        layers.append(nn.Linear(in_dim, latent_dim))\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "        layers = []\n",
        "        in_dim = latent_dim\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        layers.append(nn.Linear(in_dim, output_dim))\n",
        "        self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "        self.skip = nn.Linear(input_dim, output_dim)\n",
        "        self.output_ln = nn.LayerNorm(output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        y_pred = self.decoder(z)\n",
        "        out = y_pred + self.skip(x)\n",
        "        return self.output_ln(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b77dad97",
      "metadata": {
        "id": "b77dad97"
      },
      "source": [
        "##### Autoencoder with Residual MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3875e856",
      "metadata": {
        "id": "3875e856"
      },
      "outputs": [],
      "source": [
        "class ResidualMLPHead(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.net(x)\n",
        "\n",
        "class TranslatorRAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, output_dim, hidden_dim=512, n_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dim\n",
        "        layers.append(nn.Linear(in_dim, latent_dim))\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "        layers = []\n",
        "        in_dim = latent_dim\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        layers.append(nn.Linear(in_dim, output_dim))\n",
        "        self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "        self.residual_head = ResidualMLPHead(output_dim, hidden_dim=output_dim//2, dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        y_pred = self.decoder(z)\n",
        "        y_final = self.residual_head(y_pred)\n",
        "        return y_final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ca8294",
      "metadata": {
        "id": "f0ca8294"
      },
      "source": [
        "##### VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8af35778",
      "metadata": {
        "id": "8af35778"
      },
      "outputs": [],
      "source": [
        "class VAETranslator(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, output_dim, hidden_dims=512, n_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_dims))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dims\n",
        "        layers.append(nn.Linear(in_dim, latent_dim * 2))  # output μ and logσ\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "        # Decoder\n",
        "        layers = []\n",
        "        in_dim = latent_dim\n",
        "        for _ in range(n_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_dims))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dims\n",
        "        layers.append(nn.Linear(in_dim, output_dim))\n",
        "        self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "        # Optional residual refinement\n",
        "        self.residual_head = ResidualMLPHead(output_dim, hidden_dim=output_dim//2, dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode input → (μ, logσ)\n",
        "        stats = self.encoder(x)\n",
        "        mu, log_sigma = stats.chunk(2, dim=-1)\n",
        "        sigma = torch.exp(log_sigma)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        eps = torch.randn_like(sigma)\n",
        "        z = mu + sigma * eps\n",
        "\n",
        "        # Decode and refine\n",
        "        y_base = self.decoder(z)\n",
        "        y_final = self.residual_head(y_base)\n",
        "        return y_final, mu, log_sigma\n",
        "\n",
        "    def kl_loss(self, mu, log_sigma):\n",
        "        return -0.5 * torch.sum(1 + 2*log_sigma - mu.pow(2) - torch.exp(2*log_sigma), dim=-1).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239b35b8",
      "metadata": {
        "id": "239b35b8"
      },
      "source": [
        "### Training Loop and NCE Loss aswell as Procrustes Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8301770d",
      "metadata": {
        "id": "8301770d"
      },
      "outputs": [],
      "source": [
        "\n",
        "class QueueInfoNCELoss(nn.Module):\n",
        "    def __init__(self, dim, temperature=0.07, queue_size=4096):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.queue_size = queue_size\n",
        "        # queue shape: (queue_size, dim)\n",
        "        self.register_buffer(\"queue\", torch.randn(queue_size, dim))\n",
        "        self.queue = F.normalize(self.queue, dim=1)\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _enqueue(self, keys):\n",
        "        \"\"\"\n",
        "        keys: tensor (B, dim), already detached, normalized, on same device as queue.\n",
        "        This writes keys into the circular queue. Safe to call only AFTER backward.\n",
        "        \"\"\"\n",
        "        batch_size = keys.shape[0]\n",
        "        ptr = int(self.queue_ptr.item())\n",
        "        end_ptr = (ptr + batch_size) % self.queue_size\n",
        "\n",
        "        if end_ptr > ptr:\n",
        "            self.queue[ptr:end_ptr] = keys\n",
        "        else:\n",
        "            # wrap\n",
        "            first_len = self.queue_size - ptr\n",
        "            self.queue[ptr:] = keys[:first_len]\n",
        "            self.queue[:end_ptr] = keys[first_len:]\n",
        "        self.queue_ptr[0] = end_ptr\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "        \"\"\"\n",
        "        Computes loss using current queue as negatives but does NOT modify the queue.\n",
        "        z_i: (B, dim) predicted (text -> img)\n",
        "        z_j: (B, dim) target (image)\n",
        "        \"\"\"\n",
        "        # normalize\n",
        "        z_i = F.normalize(z_i, dim=1)\n",
        "        z_j = F.normalize(z_j, dim=1)\n",
        "\n",
        "        # positive logits: (B, 1)\n",
        "        l_pos = torch.sum(z_i * z_j, dim=-1, keepdim=True)\n",
        "\n",
        "        # negative logits from queue: (B, queue_size)\n",
        "        # queue is a buffer; safe to read\n",
        "        l_neg = torch.matmul(z_i, self.queue.T)\n",
        "\n",
        "        # logits: (B, 1 + queue_size)\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
        "        logits /= self.temperature\n",
        "\n",
        "        labels = torch.zeros(logits.size(0), dtype=torch.long, device=z_i.device)  # positives at index 0\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c24c2928",
      "metadata": {
        "id": "c24c2928"
      },
      "outputs": [],
      "source": [
        "# ====== Procrustes initialization ======\n",
        "def procrustes_init(text_embs, img_embs):\n",
        "    \"\"\"\n",
        "    text_embs: (N, d_text)\n",
        "    img_embs:  (N, d_img)\n",
        "    returns: weight matrix (d_img, d_text)\n",
        "    \"\"\"\n",
        "    # Center both\n",
        "    X = text_embs - text_embs.mean(0, keepdim=True)\n",
        "    Y = img_embs - img_embs.mean(0, keepdim=True)\n",
        "\n",
        "    # Compute SVD of cross-covariance\n",
        "    U, _, Vt = torch.linalg.svd(X.T @ Y, full_matrices=False)\n",
        "    W = U @ Vt  # orthogonal map d_text→d_img\n",
        "    return W.T   # shape (d_img, d_text) for nn.Linear weight\n",
        "\n",
        "\n",
        "def apply_procrustes_init_to_final(model, text_sample, img_sample):\n",
        "    \"\"\"\n",
        "    Apply Procrustes initialization to a model.\n",
        "    - For MLP / ResidualMLP: apply to final Linear layer (hidden -> img_dim)\n",
        "    - For TransformerTranslator: apply to first projection (text_dim -> img_dim)\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # Compute Procrustes matrix\n",
        "        W = procrustes_init(text_embs=text_sample, img_embs=img_sample)\n",
        "\n",
        "        # Apply to the appropriate layer\n",
        "        applied = False\n",
        "        for name, m in model.named_modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                # Transformer: apply to first projection (proj_in)\n",
        "                if isinstance(model, TranslatorAE) and name.endswith(\"skip\"):\n",
        "                    print(m.weight.shape, W.shape)\n",
        "                    if m.weight.shape == W.shape:\n",
        "                        m.weight.copy_(W)\n",
        "                        applied = True\n",
        "                        break\n",
        "                elif isinstance(model, TranslatorRAE) and name.endswith(\"proj_in\"):\n",
        "                    print(m.weight.shape, W.shape)\n",
        "                    if m.weight.shape == W.shape:\n",
        "                        m.weight.copy_(W)\n",
        "                        applied = True\n",
        "                        break\n",
        "                elif isinstance(model, VAETranslator) and name.endswith(\"proj_in\"):\n",
        "                    print(m.weight.shape, W.shape)\n",
        "                    if m.weight.shape == W.shape:\n",
        "                        m.weight.copy_(W)\n",
        "                        applied = True\n",
        "                        break\n",
        "\n",
        "        if not applied:\n",
        "            print(\"⚠️ Warning: Could not find matching layer for Procrustes init\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "0c5c9ab9",
      "metadata": {
        "id": "0c5c9ab9"
      },
      "outputs": [],
      "source": [
        "# ---------- Training loop with Procrustes + InfoNCE ----------\n",
        "def training(model, train_loader, val_loader, device, epochs, lr, MODEL_PATH,\n",
        "             use_procrustes_init=True, procrustes_subset=50000, temperature=0.07,\n",
        "             queue_size=4098):\n",
        "    \"\"\"Train LatentSpaceTranslator with optional Procrustes init + InfoNCE loss.\"\"\"\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-3)\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # --- Optional: Procrustes initialization ---\n",
        "    if use_procrustes_init:\n",
        "        print(\"Computing Procrustes initialization...\")\n",
        "        text_list, img_list = [], []\n",
        "        for i, (X, y) in enumerate(train_loader):\n",
        "            text_list.append(X.cpu())\n",
        "            img_list.append(y.cpu())\n",
        "            if sum(t.shape[0] for t in text_list) >= procrustes_subset:\n",
        "                break\n",
        "        text_sample = torch.cat(text_list, dim=0)[:procrustes_subset]\n",
        "        img_sample = torch.cat(img_list, dim=0)[:procrustes_subset]\n",
        "        model = apply_procrustes_init_to_final(model, text_sample, img_sample)\n",
        "\n",
        "    criterion = QueueInfoNCELoss(dim=1536, temperature=temperature, queue_size=queue_size).to(device)\n",
        "    name = model.__class__.__name__\n",
        "    # --- Training ---\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = 0.0\n",
        "            if name == \"VAETranslator\":\n",
        "                pred, mu, log_sigma = model(X_batch)\n",
        "                kl_loss = model.kl_loss(mu, log_sigma)\n",
        "                loss += 1e-4 * kl_loss\n",
        "            else:\n",
        "                pred = model(X_batch)\n",
        "            # Weighted combination of losses\n",
        "            loss += criterion(pred, y_batch)\n",
        "            loss += 1 - F.cosine_similarity(\n",
        "                F.normalize(pred, dim=-1),\n",
        "                F.normalize(y_batch, dim=-1)\n",
        "            ).mean()\n",
        "            loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              keys = F.normalize(y_batch, dim=1).detach()   # image embeddings (targets) as keys\n",
        "              # put them into the queue\n",
        "              criterion._enqueue(keys)\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                loss = 0.0\n",
        "                if name == \"VAETranslator\":\n",
        "                    pred, mu, log_sigma = model(X_batch)\n",
        "                    kl_loss = model.kl_loss(mu, log_sigma)\n",
        "                    loss += 1e-4 * kl_loss\n",
        "                else:\n",
        "                    pred = model(X_batch)\n",
        "                # Weighted combination of losses\n",
        "                loss += criterion(pred, y_batch)\n",
        "                loss += 1 - F.cosine_similarity(\n",
        "                    F.normalize(pred, dim=-1),\n",
        "                    F.normalize(y_batch, dim=-1)\n",
        "                ).mean()\n",
        "                loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                keys = F.normalize(y_batch, dim=1).detach()   # image embeddings (targets) as keys\n",
        "                criterion._enqueue(keys)\n",
        "\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n",
        "\n",
        "        # --- Save best model ---\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            Path(MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            print(f\"  ✓ Saved best model (val_loss={val_loss:.6f})\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eab59241",
      "metadata": {
        "id": "eab59241"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7e32fd7a",
      "metadata": {
        "id": "7e32fd7a",
        "outputId": "87519c07-1f2e-454f-ef7b-dd8908fd7f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125000,)\n",
            "Train data: 125000 captions, 125000 images\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([112500, 1536]), torch.Size([112500, 1024]), 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 4. Data Augmentation\n",
        "# 5. Zero Shot Stitching\n",
        "# 6. Triplet Loss / Improve InfoNCE Loss / bidirectional / SimCLR / MoCo\n",
        "# 7. Autoencoder\n",
        "# Configuration\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512\n",
        "LR = 0.001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load data\n",
        "train_data = load_data(\"drive/MyDrive/data/train/train.npz\")\n",
        "#train_data = load_data('data/train/train.npz')\n",
        "X, y, label = prepare_train_data(train_data)\n",
        "DATASET_SIZE = len(X)\n",
        "# Split train/val\n",
        "# This is done only to measure generalization capabilities, you don't have to\n",
        "# use a validation set (though we encourage this)\n",
        "n_train = int(0.9 * len(X))\n",
        "TRAIN_SPLIT = torch.zeros(len(X), dtype=torch.bool)\n",
        "TRAIN_SPLIT[:n_train] = 1\n",
        "X_train, X_val = X[TRAIN_SPLIT], X[~TRAIN_SPLIT]\n",
        "y_train, y_val = y[TRAIN_SPLIT], y[~TRAIN_SPLIT]\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "y_train.shape, X_train.shape, train_loader.batch_size, val_loader.batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebd8eb3",
      "metadata": {
        "id": "3ebd8eb3"
      },
      "source": [
        "### Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6bb135a9",
      "metadata": {
        "id": "6bb135a9",
        "outputId": "7b9127a6-f6c1-4226-a7a1-10e98d4f42c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.1)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d9df740f",
      "metadata": {
        "id": "d9df740f"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def objective_extended(arch, trial, train_dataloader, val_dataloader, device, MODEL_PATH_BASE):\n",
        "\n",
        "    # --- Common hyperparameters ---\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.3)\n",
        "    #lr = trial.suggest_loguniform(\"lr\", 5e-4, 1e-2)\n",
        "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3)\n",
        "\n",
        "    # --- New hyperparameters ---\n",
        "    temperature = trial.suggest_float(\"temperature\", 0.01, 0.2)\n",
        "    queue_size = trial.suggest_categorical(\"queue_size\", [2048, 4098, 8196])\n",
        "    #w_infonce = trial.suggest_float(\"w_infonce\", 0.6, 0.8)\n",
        "    #w_cos = trial.suggest_float(\"w_cos\", 0.4, 1.0)\n",
        "    #w_mse = trial.suggest_float(\"w_mse\", 1.0 - w_cos, 1.0)\n",
        "    procrustes_subset = 50000\n",
        "\n",
        "    # --- Architecture-specific hyperparameters ---\n",
        "    if arch in [\"AE\", \"RAE\", \"VAE\"]:\n",
        "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [512, 1024, 2048])\n",
        "        num_layers = trial.suggest_int(\"num_layers\", 2, 6)\n",
        "        if arch == \"AE\":\n",
        "            latent_dim = trial.suggest_categorical(\"latent_dim\", [1024, 1536, 2048])\n",
        "            model = TranslatorAE(\n",
        "                input_dim=1024, latent_dim=latent_dim, output_dim=1536, hidden_dim=hidden_dim,\n",
        "                n_layers=num_layers, dropout=dropout\n",
        "            ).to(device)\n",
        "        elif arch == \"RAE\":\n",
        "            latent_dim = trial.suggest_categorical(\"latent_dim\", [1024, 1536, 2048])\n",
        "            model = TranslatorRAE(\n",
        "                input_dim=1024, latent_dim=latent_dim, output_dim=1536, hidden_dim=hidden_dim,\n",
        "                n_layers=num_layers, dropout=dropout\n",
        "            ).to(device)\n",
        "        else:\n",
        "            latent_dim = trial.suggest_categorical(\"latent_dim\", [512, 768, 1024])\n",
        "            model = VAETranslator(\n",
        "                input_dim=1024, latent_dim= latent_dim, output_dim=1536, hidden_dims=hidden_dim,\n",
        "                n_layers=num_layers, dropout=dropout\n",
        "            ).to(device)\n",
        "\n",
        "    # --- Apply Procrustes initialization ---\n",
        "    if procrustes_subset > 0:\n",
        "        # Get subset from train_loader\n",
        "        text_list, img_list = [], []\n",
        "        for i, (X, y) in enumerate(train_loader):\n",
        "            text_list.append(X.cpu())\n",
        "            img_list.append(y.cpu())\n",
        "            if sum(t.shape[0] for t in text_list) >= procrustes_subset:\n",
        "                break\n",
        "        text_sample = torch.cat(text_list, dim=0)[:procrustes_subset]\n",
        "        img_sample = torch.cat(img_list, dim=0)[:procrustes_subset]\n",
        "        model = apply_procrustes_init_to_final(model, text_sample, img_sample)\n",
        "\n",
        "    criterion = QueueInfoNCELoss(dim=1536, temperature=temperature, queue_size=queue_size).to(device)\n",
        "    # --- Training loop (short run) ---\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=weight_decay)\n",
        "    model.train()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    for epoch in range(5):  # short training\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = 0.0\n",
        "            if arch == \"VAE\":\n",
        "                pred, mu, log_sigma = model(X_batch)\n",
        "                kl_loss = model.kl_loss(mu, log_sigma)\n",
        "                loss += 1e-4 * kl_loss\n",
        "            else:\n",
        "                pred = model(X_batch)\n",
        "            # Weighted combination of losses\n",
        "            loss += criterion(pred, y_batch)\n",
        "            loss += 1 - F.cosine_similarity(\n",
        "                F.normalize(pred, dim=-1),\n",
        "                F.normalize(y_batch, dim=-1)\n",
        "            ).mean()\n",
        "            loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              keys = F.normalize(y_batch, dim=1).detach()   # image embeddings (targets) as keys\n",
        "              # put them into the queue\n",
        "              criterion._enqueue(keys)\n",
        "\n",
        "    # --- Evaluate on validation ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            loss = 0.0\n",
        "            if arch == \"VAE\":\n",
        "                pred, mu, log_sigma = model(X_batch)\n",
        "                kl_loss = model.kl_loss(mu, log_sigma)\n",
        "                loss += 1e-4 * kl_loss\n",
        "            else:\n",
        "                pred = model(X_batch)\n",
        "            # Weighted combination of losses\n",
        "            loss += criterion(pred, y_batch)\n",
        "            loss += 1 - F.cosine_similarity(\n",
        "                F.normalize(pred, dim=-1),\n",
        "                F.normalize(y_batch, dim=-1)\n",
        "            ).mean()\n",
        "            loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            keys = F.normalize(y_batch, dim=1).detach()\n",
        "            criterion._enqueue(keys)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "def run_optuna_extended(arch, train_dataloader, val_dataloader, device, MODEL_PATH_BASE, n_trials=20):\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective_extended(arch, trial, train_dataloader, val_dataloader, device, MODEL_PATH_BASE),\n",
        "                   n_trials=n_trials)\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "    print(f\"Val loss: {trial.value}\")\n",
        "    print(\"Best hyperparameters:\")\n",
        "    for key, value in trial.params.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    return trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "cc717d12",
      "metadata": {
        "id": "cc717d12",
        "outputId": "2b6e5a21-0421-4886-c750-4f9693c53a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:48:51,390] A new study created in memory with name: no-name-a4cc3219-9c75-437a-b79a-216c1e0477d0\n",
            "/tmp/ipython-input-2654030903.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:49:58,774] Trial 0 finished with value: 6.606437664031983 and parameters: {'dropout': 0.10011912045944094, 'weight_decay': 0.00032382093761147067, 'temperature': 0.09045946900103656, 'queue_size': 4098, 'hidden_dim': 512, 'num_layers': 6, 'latent_dim': 2048}. Best is trial 0 with value: 6.606437664031983.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:51:44,251] Trial 1 finished with value: 5.379280509948731 and parameters: {'dropout': 0.2653587185666726, 'weight_decay': 3.336155675814686e-05, 'temperature': 0.04653578867613997, 'queue_size': 4098, 'hidden_dim': 2048, 'num_layers': 6, 'latent_dim': 1024}. Best is trial 1 with value: 5.379280509948731.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:52:30,269] Trial 2 finished with value: 6.400638256072998 and parameters: {'dropout': 0.16638782921074685, 'weight_decay': 0.00017704942855714014, 'temperature': 0.12509587590742538, 'queue_size': 2048, 'hidden_dim': 1024, 'num_layers': 2, 'latent_dim': 1024}. Best is trial 1 with value: 5.379280509948731.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:53:41,340] Trial 3 finished with value: 5.173537311553955 and parameters: {'dropout': 0.15010144494651417, 'weight_decay': 1.1398841566413616e-05, 'temperature': 0.060453491733708134, 'queue_size': 2048, 'hidden_dim': 1024, 'num_layers': 6, 'latent_dim': 2048}. Best is trial 3 with value: 5.173537311553955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:54:27,299] Trial 4 finished with value: 8.229947166442871 and parameters: {'dropout': 0.21820041702096282, 'weight_decay': 0.0009669510339900876, 'temperature': 0.1716195194589254, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 2, 'latent_dim': 2048}. Best is trial 3 with value: 5.173537311553955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:56:10,361] Trial 5 finished with value: 6.774692325592041 and parameters: {'dropout': 0.2833100160311791, 'weight_decay': 4.165857702880503e-05, 'temperature': 0.16455641501762616, 'queue_size': 2048, 'hidden_dim': 2048, 'num_layers': 6, 'latent_dim': 1024}. Best is trial 3 with value: 5.173537311553955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:57:06,324] Trial 6 finished with value: 7.274403743743896 and parameters: {'dropout': 0.16825306433282702, 'weight_decay': 2.637065764289945e-05, 'temperature': 0.138707339551641, 'queue_size': 4098, 'hidden_dim': 512, 'num_layers': 4, 'latent_dim': 1536}. Best is trial 3 with value: 5.173537311553955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:58:09,251] Trial 7 finished with value: 6.561344184875488 and parameters: {'dropout': 0.19113453060020777, 'weight_decay': 1.241795865443377e-05, 'temperature': 0.1381541280700273, 'queue_size': 2048, 'hidden_dim': 1024, 'num_layers': 5, 'latent_dim': 1024}. Best is trial 3 with value: 5.173537311553955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 18:59:09,877] Trial 8 finished with value: 6.925979461669922 and parameters: {'dropout': 0.1473139348373667, 'weight_decay': 0.00037022343367573826, 'temperature': 0.07327224915044685, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 5, 'latent_dim': 2048}. Best is trial 3 with value: 5.173537311553955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:00:05,091] Trial 9 finished with value: 4.976639881134033 and parameters: {'dropout': 0.23308854565786985, 'weight_decay': 0.00017371071242602062, 'temperature': 0.02156883643692692, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 4, 'latent_dim': 1024}. Best is trial 9 with value: 4.976639881134033.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:00:55,243] Trial 10 finished with value: 4.792838516235352 and parameters: {'dropout': 0.23683742652777356, 'weight_decay': 8.469806899815575e-05, 'temperature': 0.013002875636706032, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 3, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:01:45,767] Trial 11 finished with value: 4.80390100479126 and parameters: {'dropout': 0.24057771278452408, 'weight_decay': 9.337826084573294e-05, 'temperature': 0.015958234851807116, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 3, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:02:35,773] Trial 12 finished with value: 4.802303619384766 and parameters: {'dropout': 0.24882502208608342, 'weight_decay': 8.291306558275999e-05, 'temperature': 0.012503188997740566, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 3, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:03:25,287] Trial 13 finished with value: 5.76406795501709 and parameters: {'dropout': 0.29808946298330774, 'weight_decay': 7.928269342021618e-05, 'temperature': 0.03878851222437381, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 3, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:04:15,007] Trial 14 finished with value: 4.810356693267822 and parameters: {'dropout': 0.2536565316341346, 'weight_decay': 5.820384221942449e-05, 'temperature': 0.011848211187552006, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 3, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:05:28,008] Trial 15 finished with value: 8.34574249267578 and parameters: {'dropout': 0.20781904219275782, 'weight_decay': 0.00015532518433213307, 'temperature': 0.19510241719425372, 'queue_size': 8196, 'hidden_dim': 2048, 'num_layers': 3, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:06:23,164] Trial 16 finished with value: 7.160979518890381 and parameters: {'dropout': 0.2688878907597194, 'weight_decay': 1.9720421844141694e-05, 'temperature': 0.08322645759854032, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 4, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:07:07,843] Trial 17 finished with value: 5.832325115203857 and parameters: {'dropout': 0.22958404470729166, 'weight_decay': 5.735091253715288e-05, 'temperature': 0.04042071975621331, 'queue_size': 8196, 'hidden_dim': 512, 'num_layers': 2, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:08:20,569] Trial 18 finished with value: 7.6107992172241214 and parameters: {'dropout': 0.19386887663067237, 'weight_decay': 0.0003602741232686485, 'temperature': 0.11032589588283426, 'queue_size': 8196, 'hidden_dim': 2048, 'num_layers': 3, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-12 19:09:19,122] Trial 19 finished with value: 5.938387470245361 and parameters: {'dropout': 0.24732079297156828, 'weight_decay': 0.00011905210803728367, 'temperature': 0.06278772333742233, 'queue_size': 4098, 'hidden_dim': 1024, 'num_layers': 4, 'latent_dim': 1536}. Best is trial 10 with value: 4.792838516235352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "Val loss: 4.792838516235352\n",
            "Best hyperparameters:\n",
            "  dropout: 0.23683742652777356\n",
            "  weight_decay: 8.469806899815575e-05\n",
            "  temperature: 0.013002875636706032\n",
            "  queue_size: 8196\n",
            "  hidden_dim: 512\n",
            "  num_layers: 3\n",
            "  latent_dim: 1536\n"
          ]
        }
      ],
      "source": [
        "archs = ['AE', 'RAE', 'VAE']\n",
        "choosen_arch = archs[0]\n",
        "best_params = run_optuna_extended(\n",
        "    arch = choosen_arch,\n",
        "    train_dataloader=train_loader,\n",
        "    val_dataloader=val_loader,\n",
        "    device=DEVICE,\n",
        "    MODEL_PATH_BASE=\"models/translator_optuna\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "57069a83",
      "metadata": {
        "id": "57069a83"
      },
      "outputs": [],
      "source": [
        "if choosen_arch == 'AE':\n",
        "    model = TranslatorAE(\n",
        "        input_dim=1024,\n",
        "        latent_dim=best_params['latent_dim'],\n",
        "        output_dim=1536,\n",
        "        hidden_dim=best_params['hidden_dim'],\n",
        "        n_layers=best_params['num_layers'],\n",
        "        dropout=best_params['dropout']\n",
        "    ).to(DEVICE)\n",
        "    MODEL_PATH = \"drive/MyDrive/data//models/AE.pth\"\n",
        "\n",
        "elif choosen_arch == 'RAE':\n",
        "    model = TranslatorRAE(\n",
        "    input_dim=1024,\n",
        "    latent_dim=best_params[\"latent_dim\"],\n",
        "    output_dim=1536,\n",
        "    hidden_dim=best_params[\"hidden_dim\"],\n",
        "    n_layers=best_params[\"num_layers\"],\n",
        "    dropout=best_params[\"dropout\"]).to(DEVICE)\n",
        "    MODEL_PATH = \"drive/MyDrive/data/models/RAE.pth\"\n",
        "\n",
        "else:\n",
        "    model = VAETranslator(\n",
        "    input_dim=1024,\n",
        "    latent_dim=best_params[\"latent_dim\"],\n",
        "    output_dim=1536,\n",
        "    hidden_dims=best_params[\"hidden_dim\"],\n",
        "    n_layers=best_params[\"num_layers\"],\n",
        "    dropout=best_params[\"dropout\"]).to(DEVICE)\n",
        "    MODEL_PATH = \"drive/MyDrive/data/models/VAE.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "df3c54d1",
      "metadata": {
        "id": "df3c54d1",
        "outputId": "1138bcb0-6cd5-48f5-ebe8-0de8507d9bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Parameters: 5,515,776\n",
            "\n",
            "3. Training...\n",
            "Computing Procrustes initialization...\n",
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 220/220 [00:09<00:00, 23.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 6.293506, Val Loss = 5.763309\n",
            "  ✓ Saved best model (val_loss=5.763309)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 220/220 [00:09<00:00, 24.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 5.236031, Val Loss = 5.329469\n",
            "  ✓ Saved best model (val_loss=5.329469)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 220/220 [00:08<00:00, 25.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 4.953081, Val Loss = 5.158429\n",
            "  ✓ Saved best model (val_loss=5.158429)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 220/220 [00:09<00:00, 24.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 4.777521, Val Loss = 5.027169\n",
            "  ✓ Saved best model (val_loss=5.027169)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 220/220 [00:09<00:00, 22.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 4.642517, Val Loss = 4.941216\n",
            "  ✓ Saved best model (val_loss=4.941216)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 220/220 [00:08<00:00, 25.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss = 4.534069, Val Loss = 4.882436\n",
            "  ✓ Saved best model (val_loss=4.882436)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 220/220 [00:09<00:00, 24.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss = 4.449714, Val Loss = 4.819399\n",
            "  ✓ Saved best model (val_loss=4.819399)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 220/220 [00:09<00:00, 23.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss = 4.379262, Val Loss = 4.774995\n",
            "  ✓ Saved best model (val_loss=4.774995)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 220/220 [00:09<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss = 4.316588, Val Loss = 4.744546\n",
            "  ✓ Saved best model (val_loss=4.744546)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 220/220 [00:08<00:00, 26.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 4.263379, Val Loss = 4.715700\n",
            "  ✓ Saved best model (val_loss=4.715700)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 220/220 [00:09<00:00, 23.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss = 4.217691, Val Loss = 4.690858\n",
            "  ✓ Saved best model (val_loss=4.690858)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 220/220 [00:09<00:00, 23.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss = 4.174939, Val Loss = 4.666406\n",
            "  ✓ Saved best model (val_loss=4.666406)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 220/220 [00:09<00:00, 24.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss = 4.139694, Val Loss = 4.644079\n",
            "  ✓ Saved best model (val_loss=4.644079)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 220/220 [00:08<00:00, 26.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss = 4.102861, Val Loss = 4.633127\n",
            "  ✓ Saved best model (val_loss=4.633127)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 220/220 [00:09<00:00, 23.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss = 4.072630, Val Loss = 4.618204\n",
            "  ✓ Saved best model (val_loss=4.618204)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 220/220 [00:09<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss = 4.045108, Val Loss = 4.600361\n",
            "  ✓ Saved best model (val_loss=4.600361)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 220/220 [00:08<00:00, 25.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Loss = 4.016611, Val Loss = 4.588201\n",
            "  ✓ Saved best model (val_loss=4.588201)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 220/220 [00:09<00:00, 23.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss = 3.991897, Val Loss = 4.581841\n",
            "  ✓ Saved best model (val_loss=4.581841)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 220/220 [00:09<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss = 3.969811, Val Loss = 4.566710\n",
            "  ✓ Saved best model (val_loss=4.566710)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 220/220 [00:09<00:00, 24.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss = 3.945901, Val Loss = 4.563715\n",
            "  ✓ Saved best model (val_loss=4.563715)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 220/220 [00:08<00:00, 25.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Loss = 3.926207, Val Loss = 4.545422\n",
            "  ✓ Saved best model (val_loss=4.545422)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 220/220 [00:09<00:00, 23.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Loss = 3.908296, Val Loss = 4.534411\n",
            "  ✓ Saved best model (val_loss=4.534411)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 220/220 [00:09<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Train Loss = 3.885849, Val Loss = 4.535943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 220/220 [00:08<00:00, 26.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Train Loss = 3.868730, Val Loss = 4.528841\n",
            "  ✓ Saved best model (val_loss=4.528841)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 220/220 [00:09<00:00, 24.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Train Loss = 3.850063, Val Loss = 4.521378\n",
            "  ✓ Saved best model (val_loss=4.521378)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 220/220 [00:09<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Train Loss = 3.835924, Val Loss = 4.514630\n",
            "  ✓ Saved best model (val_loss=4.514630)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 220/220 [00:09<00:00, 23.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Train Loss = 3.818193, Val Loss = 4.506412\n",
            "  ✓ Saved best model (val_loss=4.506412)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 220/220 [00:08<00:00, 26.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Train Loss = 3.803865, Val Loss = 4.499660\n",
            "  ✓ Saved best model (val_loss=4.499660)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 220/220 [00:09<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Train Loss = 3.788118, Val Loss = 4.499565\n",
            "  ✓ Saved best model (val_loss=4.499565)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 220/220 [00:09<00:00, 22.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Train Loss = 3.775218, Val Loss = 4.490725\n",
            "  ✓ Saved best model (val_loss=4.490725)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 220/220 [00:08<00:00, 26.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Train Loss = 3.761771, Val Loss = 4.485536\n",
            "  ✓ Saved best model (val_loss=4.485536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 220/220 [00:09<00:00, 23.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Train Loss = 3.746613, Val Loss = 4.481338\n",
            "  ✓ Saved best model (val_loss=4.481338)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 220/220 [00:09<00:00, 23.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Train Loss = 3.732270, Val Loss = 4.479864\n",
            "  ✓ Saved best model (val_loss=4.479864)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 220/220 [00:09<00:00, 22.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Train Loss = 3.719470, Val Loss = 4.473000\n",
            "  ✓ Saved best model (val_loss=4.473000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 220/220 [00:08<00:00, 26.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Train Loss = 3.708820, Val Loss = 4.472088\n",
            "  ✓ Saved best model (val_loss=4.472088)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 220/220 [00:09<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Train Loss = 3.695882, Val Loss = 4.466965\n",
            "  ✓ Saved best model (val_loss=4.466965)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 220/220 [00:09<00:00, 23.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Train Loss = 3.682862, Val Loss = 4.461379\n",
            "  ✓ Saved best model (val_loss=4.461379)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 220/220 [00:09<00:00, 24.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Train Loss = 3.674589, Val Loss = 4.461565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 220/220 [00:08<00:00, 25.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Train Loss = 3.662640, Val Loss = 4.459600\n",
            "  ✓ Saved best model (val_loss=4.459600)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 220/220 [00:09<00:00, 23.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Train Loss = 3.651554, Val Loss = 4.452475\n",
            "  ✓ Saved best model (val_loss=4.452475)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 220/220 [00:09<00:00, 22.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Train Loss = 3.641567, Val Loss = 4.450024\n",
            "  ✓ Saved best model (val_loss=4.450024)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 220/220 [00:08<00:00, 26.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Train Loss = 3.630697, Val Loss = 4.450016\n",
            "  ✓ Saved best model (val_loss=4.450016)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 220/220 [00:09<00:00, 23.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Train Loss = 3.619734, Val Loss = 4.442074\n",
            "  ✓ Saved best model (val_loss=4.442074)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 220/220 [00:09<00:00, 23.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Train Loss = 3.611053, Val Loss = 4.438085\n",
            "  ✓ Saved best model (val_loss=4.438085)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 220/220 [00:08<00:00, 25.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Train Loss = 3.601037, Val Loss = 4.439276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 220/220 [00:09<00:00, 24.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: Train Loss = 3.589753, Val Loss = 4.442805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 220/220 [00:09<00:00, 23.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: Train Loss = 3.580733, Val Loss = 4.430598\n",
            "  ✓ Saved best model (val_loss=4.430598)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 220/220 [00:09<00:00, 23.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: Train Loss = 3.571374, Val Loss = 4.433004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 220/220 [00:08<00:00, 25.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: Train Loss = 3.565524, Val Loss = 4.429566\n",
            "  ✓ Saved best model (val_loss=4.429566)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 220/220 [00:09<00:00, 23.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50: Train Loss = 3.554340, Val Loss = 4.433814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 220/220 [00:09<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51: Train Loss = 3.545660, Val Loss = 4.428038\n",
            "  ✓ Saved best model (val_loss=4.428038)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 220/220 [00:08<00:00, 25.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52: Train Loss = 3.538560, Val Loss = 4.428117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 220/220 [00:09<00:00, 22.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53: Train Loss = 3.530968, Val Loss = 4.426400\n",
            "  ✓ Saved best model (val_loss=4.426400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 220/220 [00:09<00:00, 23.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54: Train Loss = 3.521139, Val Loss = 4.421060\n",
            "  ✓ Saved best model (val_loss=4.421060)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 220/220 [00:09<00:00, 23.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55: Train Loss = 3.514233, Val Loss = 4.420193\n",
            "  ✓ Saved best model (val_loss=4.420193)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 220/220 [00:08<00:00, 25.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56: Train Loss = 3.504632, Val Loss = 4.417683\n",
            "  ✓ Saved best model (val_loss=4.417683)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 220/220 [00:09<00:00, 23.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57: Train Loss = 3.498297, Val Loss = 4.418148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 220/220 [00:09<00:00, 23.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58: Train Loss = 3.487796, Val Loss = 4.415196\n",
            "  ✓ Saved best model (val_loss=4.415196)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 220/220 [00:08<00:00, 26.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59: Train Loss = 3.482982, Val Loss = 4.414967\n",
            "  ✓ Saved best model (val_loss=4.414967)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 220/220 [00:09<00:00, 22.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60: Train Loss = 3.475713, Val Loss = 4.418942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 220/220 [00:09<00:00, 24.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61: Train Loss = 3.469906, Val Loss = 4.407254\n",
            "  ✓ Saved best model (val_loss=4.407254)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 220/220 [00:09<00:00, 24.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62: Train Loss = 3.461160, Val Loss = 4.410604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 220/220 [00:08<00:00, 25.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63: Train Loss = 3.454567, Val Loss = 4.407612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 220/220 [00:09<00:00, 23.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64: Train Loss = 3.448523, Val Loss = 4.404198\n",
            "  ✓ Saved best model (val_loss=4.404198)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 220/220 [00:09<00:00, 22.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65: Train Loss = 3.440342, Val Loss = 4.403581\n",
            "  ✓ Saved best model (val_loss=4.403581)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 220/220 [00:08<00:00, 25.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66: Train Loss = 3.432615, Val Loss = 4.411491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 220/220 [00:09<00:00, 22.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67: Train Loss = 3.427639, Val Loss = 4.407057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 220/220 [00:09<00:00, 23.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68: Train Loss = 3.420108, Val Loss = 4.404116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 220/220 [00:08<00:00, 25.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69: Train Loss = 3.413754, Val Loss = 4.407080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 220/220 [00:08<00:00, 25.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70: Train Loss = 3.405483, Val Loss = 4.403200\n",
            "  ✓ Saved best model (val_loss=4.403200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 220/220 [00:09<00:00, 23.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71: Train Loss = 3.400195, Val Loss = 4.405035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 220/220 [00:09<00:00, 23.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72: Train Loss = 3.393671, Val Loss = 4.393280\n",
            "  ✓ Saved best model (val_loss=4.393280)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 220/220 [00:08<00:00, 26.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73: Train Loss = 3.387812, Val Loss = 4.397047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 220/220 [00:09<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74: Train Loss = 3.382617, Val Loss = 4.395593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 220/220 [00:09<00:00, 23.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75: Train Loss = 3.376375, Val Loss = 4.398875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 220/220 [00:08<00:00, 26.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76: Train Loss = 3.368483, Val Loss = 4.389352\n",
            "  ✓ Saved best model (val_loss=4.389352)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 220/220 [00:09<00:00, 23.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77: Train Loss = 3.363503, Val Loss = 4.399396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 220/220 [00:09<00:00, 22.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78: Train Loss = 3.358511, Val Loss = 4.391198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 220/220 [00:09<00:00, 23.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79: Train Loss = 3.351131, Val Loss = 4.392106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 220/220 [00:08<00:00, 26.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80: Train Loss = 3.347170, Val Loss = 4.397952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 220/220 [00:09<00:00, 23.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81: Train Loss = 3.340952, Val Loss = 4.388542\n",
            "  ✓ Saved best model (val_loss=4.388542)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 220/220 [00:09<00:00, 23.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82: Train Loss = 3.333778, Val Loss = 4.392952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 220/220 [00:08<00:00, 25.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83: Train Loss = 3.328652, Val Loss = 4.401352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 220/220 [00:09<00:00, 24.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84: Train Loss = 3.325270, Val Loss = 4.392835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 220/220 [00:09<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85: Train Loss = 3.318302, Val Loss = 4.387938\n",
            "  ✓ Saved best model (val_loss=4.387938)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 220/220 [00:08<00:00, 25.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86: Train Loss = 3.315341, Val Loss = 4.387193\n",
            "  ✓ Saved best model (val_loss=4.387193)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 220/220 [00:09<00:00, 24.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87: Train Loss = 3.308742, Val Loss = 4.385248\n",
            "  ✓ Saved best model (val_loss=4.385248)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 220/220 [00:09<00:00, 23.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88: Train Loss = 3.303177, Val Loss = 4.387883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 220/220 [00:09<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89: Train Loss = 3.299121, Val Loss = 4.385766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 220/220 [00:08<00:00, 26.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90: Train Loss = 3.291739, Val Loss = 4.389777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 220/220 [00:09<00:00, 23.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91: Train Loss = 3.287430, Val Loss = 4.390826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 220/220 [00:09<00:00, 23.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92: Train Loss = 3.282601, Val Loss = 4.380790\n",
            "  ✓ Saved best model (val_loss=4.380790)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 220/220 [00:08<00:00, 25.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93: Train Loss = 3.277838, Val Loss = 4.390615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 220/220 [00:09<00:00, 23.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94: Train Loss = 3.270546, Val Loss = 4.390339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 220/220 [00:09<00:00, 23.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95: Train Loss = 3.267782, Val Loss = 4.381950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 220/220 [00:08<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96: Train Loss = 3.262965, Val Loss = 4.386014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 220/220 [00:08<00:00, 25.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97: Train Loss = 3.256033, Val Loss = 4.393468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 220/220 [00:09<00:00, 23.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98: Train Loss = 3.253084, Val Loss = 4.390576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 220/220 [00:09<00:00, 23.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99: Train Loss = 3.248466, Val Loss = 4.386397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 220/220 [00:08<00:00, 26.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100: Train Loss = 3.243366, Val Loss = 4.383807\n"
          ]
        }
      ],
      "source": [
        "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train\n",
        "print(\"\\n3. Training...\")\n",
        "model = training(model,\n",
        "                 train_loader,\n",
        "                 val_loader,\n",
        "                 DEVICE,\n",
        "                 EPOCHS,\n",
        "                 1e-5,\n",
        "                 MODEL_PATH,\n",
        "                 True,\n",
        "                 10000,\n",
        "                 best_params[\"temperature\"],\n",
        "                 best_params[\"queue_size\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a14921c2",
      "metadata": {
        "id": "a14921c2",
        "outputId": "129b9e74-f2ab-41b8-a158-8c223b06aee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating submission file...\n",
            "✓ Saved submission to AE_submission.csv\n",
            "Model saved to: drive/MyDrive/data//models/AE.pth\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "test_data = load_data(\"drive/MyDrive/data/test/test.clean.npz\")\n",
        "\n",
        "test_embds = test_data['captions/embeddings']\n",
        "test_embds = torch.from_numpy(test_embds).float()\n",
        "\n",
        "with torch.no_grad():\n",
        "    if choosen_arch == 'VAE':\n",
        "      pred_embds, _, _ = model(test_embds.to(DEVICE))\n",
        "      pred_embds = pred_embds.cpu()\n",
        "    else:\n",
        "      pred_embds = model(test_embds.to(DEVICE)).cpu()\n",
        "\n",
        "submission = generate_submission(test_data['captions/ids'], pred_embds, f'{choosen_arch}_submission.csv')\n",
        "print(f\"Model saved to: {MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ETZG7Z7P6LMW"
      },
      "id": "ETZG7Z7P6LMW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}