{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "297c7b43",
      "metadata": {
        "id": "297c7b43"
      },
      "source": [
        "## Notebook for Constrastive Learning + linear alignment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eda159a",
      "metadata": {
        "id": "7eda159a"
      },
      "source": [
        "### Import Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45f4af51",
      "metadata": {
        "id": "45f4af51",
        "outputId": "6986b255-47c0-446d-d3f4-64c21004bc54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'challenge' already exists and is not an empty directory.\n",
            "--2025-11-11 15:15:16--  https://raw.githubusercontent.com/tam4x/aml_challenge/dac7ecf90d05ea8c77c851ea932a569c1cd4fc99/preprocess_data.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7062 (6.9K) [text/plain]\n",
            "Saving to: ‘preprocess_data.py’\n",
            "\n",
            "preprocess_data.py  100%[===================>]   6.90K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-11 15:15:16 (107 MB/s) - ‘preprocess_data.py’ saved [7062/7062]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!mkdir data\n",
        "#!gdown 1CVAQDuPOiwm8h9LJ8a_oOs6zOWS6EgkB\n",
        "#!gdown 1ykZ9fjTxUwdiEwqagoYZiMcD5aG-7rHe\n",
        "#!unzip -o test.zip -d data\n",
        "#!unzip -o train.zip -d data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/Mamiglia/challenge.git\n",
        "!wget https://raw.githubusercontent.com/tam4x/aml_challenge/dac7ecf90d05ea8c77c851ea932a569c1cd4fc99/preprocess_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8140ee3f",
      "metadata": {
        "id": "8140ee3f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "from challenge.src.common import load_data, prepare_train_data, generate_submission"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess_data.py drive/MyDrive/data/train"
      ],
      "metadata": {
        "id": "l1XGOxm-fGYn",
        "outputId": "e54562b7-1adc-4173-e3d6-d15ebd403ad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l1XGOxm-fGYn",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-11 15:15:52.327417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762874152.347221   10065 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762874152.353177   10065 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762874152.370134   10065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762874152.370158   10065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762874152.370163   10065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762874152.370167   10065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-11 15:15:52.375357: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using device: cuda\n",
            "Loading text model: sentence-transformers/roberta-large-nli-stsb-mean-tokens\n",
            "Loading image model: facebook/dinov2-giant\n",
            "Loading dataset from: drive/MyDrive/data/train\n",
            "Found 25000 images and 125000 total captions.\n",
            "Processing 25000 images in batches...\n",
            "Encoding augmented images:   0% 35/25000 [00:25<5:05:25,  1.36it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/preprocess_data.py\", line 186, in <module>\n",
            "    main()\n",
            "  File \"/content/preprocess_data.py\", line 183, in main\n",
            "    create_data_file(args.input_folder, args.output_file, args.device, args)\n",
            "  File \"/content/preprocess_data.py\", line 130, in create_data_file\n",
            "    all_images, img_embd = process_images_batch(image_processor, \n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/preprocess_data.py\", line 71, in process_images_batch\n",
            "    emb = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e582da8c",
      "metadata": {
        "id": "e582da8c"
      },
      "source": [
        "### Create Neural Network Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335ff8ba",
      "metadata": {
        "id": "335ff8ba"
      },
      "outputs": [],
      "source": [
        "class TransformerTranslator(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer-style translator from text embedding -> image embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, text_dim=1024, img_dim=1536, n_heads=8, n_layers=2, dim_feedforward=2048, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.input_ln = nn.LayerNorm(text_dim)\n",
        "        self.proj_in = nn.Linear(text_dim, img_dim)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=img_dim,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation='gelu',\n",
        "            batch_first=True  # for (B, Seq, Dim)\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "        self.output_ln = nn.LayerNorm(img_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)  # (B, 1, text_dim)\n",
        "        x = self.input_ln(x)\n",
        "        x = self.proj_in(x)  # project to model dim\n",
        "        out = self.encoder(x)  # Transformer encoder\n",
        "        out = out.squeeze(1)   # remove sequence dim\n",
        "        return self.output_ln(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42f54c4",
      "metadata": {
        "id": "e42f54c4"
      },
      "outputs": [],
      "source": [
        "class ResidualMLPTranslator(nn.Module):\n",
        "    def __init__(self, text_dim=1024, img_dim=1536, hidden_dim=2048, num_layers=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        assert num_layers >= 2\n",
        "        self.input_ln = nn.LayerNorm(text_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # first layer: text_dim -> hidden_dim (no residual yet)\n",
        "        self.first_layer = nn.Sequential(\n",
        "            nn.Linear(text_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # hidden residual blocks (hidden_dim -> hidden_dim)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            )\n",
        "            for _ in range(num_layers - 2)\n",
        "        ])\n",
        "\n",
        "        # final projection to image space\n",
        "        self.final_proj = nn.Linear(hidden_dim, img_dim)\n",
        "        self.output_ln = nn.LayerNorm(img_dim)\n",
        "\n",
        "        # input residual to output\n",
        "        if text_dim != img_dim:\n",
        "            self.res_proj = nn.Linear(text_dim, img_dim)\n",
        "        else:\n",
        "            self.res_proj = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_in = self.input_ln(x)\n",
        "        out = self.first_layer(x_in)\n",
        "        for block in self.blocks:\n",
        "            out = out + block(out)  # residual only between same-dim layers\n",
        "        out = self.final_proj(out)\n",
        "        out = out + self.res_proj(x_in)\n",
        "        return self.output_ln(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f345ba96",
      "metadata": {
        "id": "f345ba96"
      },
      "outputs": [],
      "source": [
        "class LatentSpaceTranslator(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP translator from text embedding -> image embedding\n",
        "    Input: text_emb (batch, text_dim) or (batch, 1, text_dim)\n",
        "    Output: (batch, img_dim)\n",
        "    Regularization: dropout, LayerNorm, GELU, residual (optional projector)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 text_dim=1024,\n",
        "                 img_dim=1536,\n",
        "                 hidden_dim=2048,\n",
        "                 num_layers=3,\n",
        "                 dropout=0.2,\n",
        "                 use_residual=True):\n",
        "        super().__init__()\n",
        "        assert num_layers >= 2, \"num_layers should be >= 2 (including final proj)\"\n",
        "        self.use_residual = use_residual\n",
        "        self.input_ln = nn.LayerNorm(text_dim)\n",
        "        layers = []\n",
        "        in_dim = text_dim\n",
        "        for i in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.LayerNorm(hidden_dim))\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dim\n",
        "        # final projection to image space\n",
        "        layers.append(nn.Linear(in_dim, img_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "        # if using residual, project input to img_dim to add it at the end\n",
        "        if self.use_residual:\n",
        "            if text_dim != img_dim:\n",
        "                self.res_proj = nn.Linear(text_dim, img_dim)\n",
        "            else:\n",
        "                self.res_proj = nn.Identity()\n",
        "\n",
        "        # final layer norm in image space\n",
        "        self.output_ln = nn.LayerNorm(img_dim)\n",
        "\n",
        "    def forward(self, text_emb):\n",
        "        if text_emb.dim() == 3:\n",
        "            x = text_emb.squeeze(1)\n",
        "        else:\n",
        "            x = text_emb\n",
        "        x = self.input_ln(x)\n",
        "        out = self.net(x)  # (B, img_dim)\n",
        "        if self.use_residual:\n",
        "            res = self.res_proj(x)\n",
        "            out = out + res\n",
        "        return self.output_ln(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed01a19b",
      "metadata": {
        "id": "ed01a19b"
      },
      "source": [
        "### Training Loop and NCE Loss aswell as Procrustes Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e729786d",
      "metadata": {
        "id": "e729786d"
      },
      "outputs": [],
      "source": [
        "\n",
        "class QueueInfoNCELoss(nn.Module):\n",
        "    def __init__(self, dim, temperature=0.07, queue_size=4096):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.queue_size = queue_size\n",
        "        # queue shape: (queue_size, dim)\n",
        "        self.register_buffer(\"queue\", torch.randn(queue_size, dim))\n",
        "        self.queue = F.normalize(self.queue, dim=1)\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _enqueue(self, keys):\n",
        "        \"\"\"\n",
        "        keys: tensor (B, dim), already detached, normalized, on same device as queue.\n",
        "        This writes keys into the circular queue. Safe to call only AFTER backward.\n",
        "        \"\"\"\n",
        "        batch_size = keys.shape[0]\n",
        "        ptr = int(self.queue_ptr.item())\n",
        "        end_ptr = (ptr + batch_size) % self.queue_size\n",
        "\n",
        "        if end_ptr > ptr:\n",
        "            self.queue[ptr:end_ptr] = keys\n",
        "        else:\n",
        "            # wrap\n",
        "            first_len = self.queue_size - ptr\n",
        "            self.queue[ptr:] = keys[:first_len]\n",
        "            self.queue[:end_ptr] = keys[first_len:]\n",
        "        self.queue_ptr[0] = end_ptr\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "        \"\"\"\n",
        "        Computes loss using current queue as negatives but does NOT modify the queue.\n",
        "        z_i: (B, dim) predicted (text -> img)\n",
        "        z_j: (B, dim) target (image)\n",
        "        \"\"\"\n",
        "        # normalize\n",
        "        z_i = F.normalize(z_i, dim=1)\n",
        "        z_j = F.normalize(z_j, dim=1)\n",
        "\n",
        "        # positive logits: (B, 1)\n",
        "        l_pos = torch.sum(z_i * z_j, dim=-1, keepdim=True)\n",
        "\n",
        "        # negative logits from queue: (B, queue_size)\n",
        "        # queue is a buffer; safe to read\n",
        "        l_neg = torch.matmul(z_i, self.queue.T)\n",
        "\n",
        "        # logits: (B, 1 + queue_size)\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
        "        logits /= self.temperature\n",
        "\n",
        "        labels = torch.zeros(logits.size(0), dtype=torch.long, device=z_i.device)  # positives at index 0\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f1f386",
      "metadata": {
        "id": "82f1f386"
      },
      "outputs": [],
      "source": [
        "# ====== Procrustes initialization ======\n",
        "def procrustes_init(text_embs, img_embs):\n",
        "    \"\"\"\n",
        "    text_embs: (N, d_text)\n",
        "    img_embs:  (N, d_img)\n",
        "    returns: weight matrix (d_img, d_text)\n",
        "    \"\"\"\n",
        "    # Center both\n",
        "    X = text_embs - text_embs.mean(0, keepdim=True)\n",
        "    Y = img_embs - img_embs.mean(0, keepdim=True)\n",
        "\n",
        "    # Compute SVD of cross-covariance\n",
        "    U, _, Vt = torch.linalg.svd(X.T @ Y, full_matrices=False)\n",
        "    W = U @ Vt  # orthogonal map d_text→d_img\n",
        "    return W.T   # shape (d_img, d_text) for nn.Linear weight\n",
        "\n",
        "\n",
        "def apply_procrustes_init_to_final(model, text_sample, img_sample):\n",
        "    \"\"\"\n",
        "    Apply Procrustes initialization to a model.\n",
        "    - For MLP / ResidualMLP: apply to final Linear layer (hidden -> img_dim)\n",
        "    - For TransformerTranslator: apply to first projection (text_dim -> img_dim)\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # Compute Procrustes matrix\n",
        "        W = procrustes_init(text_embs=text_sample, img_embs=img_sample)\n",
        "\n",
        "        # Apply to the appropriate layer\n",
        "        applied = False\n",
        "        for name, m in model.named_modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                # Transformer: apply to first projection (proj_in)\n",
        "                if isinstance(model, TransformerTranslator) and name.endswith(\"proj_in\"):\n",
        "                    print(m.weight.shape, W.shape)\n",
        "                    if m.weight.shape == W.shape:\n",
        "                        m.weight.copy_(W)\n",
        "                        applied = True\n",
        "                        break\n",
        "                # MLP / ResidualMLP: apply to final_proj\n",
        "                elif isinstance(model, LatentSpaceTranslator) and name.endswith(\"res_proj\"):\n",
        "                    print(m.weight.shape, W.shape)\n",
        "                    if m.weight.shape == W.shape:\n",
        "                        m.weight.copy_(W)\n",
        "                        applied = True\n",
        "                        break\n",
        "\n",
        "                elif isinstance(model, ResidualMLPTranslator) and name.endswith(\"res_proj\"):\n",
        "                    print(m.weight.shape, W.shape)\n",
        "                    if m.weight.shape == W.shape:\n",
        "                        m.weight.copy_(W)\n",
        "                        applied = True\n",
        "                        break\n",
        "\n",
        "        if not applied:\n",
        "            print(\"⚠️ Warning: Could not find matching layer for Procrustes init\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b2b396",
      "metadata": {
        "id": "e7b2b396"
      },
      "outputs": [],
      "source": [
        "# ---------- Training loop with Procrustes + InfoNCE ----------\n",
        "def training(model, train_loader, val_loader, device, epochs, lr, MODEL_PATH,\n",
        "             use_procrustes_init=True, procrustes_subset=10000, temperature=0.07,\n",
        "             queue_size=4098):\n",
        "    \"\"\"Train LatentSpaceTranslator with optional Procrustes init + InfoNCE loss.\"\"\"\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-3)\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # --- Optional: Procrustes initialization ---\n",
        "    if use_procrustes_init:\n",
        "        print(\"Computing Procrustes initialization...\")\n",
        "        text_list, img_list = [], []\n",
        "        for i, (X, y) in enumerate(train_loader):\n",
        "            text_list.append(X.cpu())\n",
        "            img_list.append(y.cpu())\n",
        "            if sum(t.shape[0] for t in text_list) >= procrustes_subset:\n",
        "                break\n",
        "        text_sample = torch.cat(text_list, dim=0)[:procrustes_subset]\n",
        "        img_sample = torch.cat(img_list, dim=0)[:procrustes_subset]\n",
        "        model = apply_procrustes_init_to_final(model, text_sample, img_sample)\n",
        "\n",
        "    criterion = QueueInfoNCELoss(dim=1536, temperature=temperature, queue_size=queue_size).to(device)\n",
        "\n",
        "    # --- Training ---\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(X_batch)\n",
        "            loss = criterion(pred, y_batch)\n",
        "            #loss += w_infonce * info_nce_loss(pred, y_batch, temperature=temperature)\n",
        "            loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "            loss += 0.1 * (1 - F.cosine_similarity(pred, y_batch).mean())\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              keys = F.normalize(y_batch, dim=1).detach()   # image embeddings (targets) as keys\n",
        "              # put them into the queue\n",
        "              criterion._enqueue(keys)\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                pred = model(X_batch)\n",
        "                loss = criterion(pred, y_batch)\n",
        "                #loss += w_infonce * info_nce_loss(pred, y_batch, temperature=temperature)\n",
        "                loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "                loss += 0.1 * (1 - F.cosine_similarity(pred, y_batch).mean())\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                keys = F.normalize(y_batch, dim=1).detach()   # image embeddings (targets) as keys\n",
        "                criterion._enqueue(keys)\n",
        "\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n",
        "\n",
        "        # --- Save best model ---\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            Path(MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            print(f\"  ✓ Saved best model (val_loss={val_loss:.6f})\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e41a65",
      "metadata": {
        "id": "c4e41a65"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1a3e15",
      "metadata": {
        "id": "fe1a3e15",
        "outputId": "06bc32cb-7256-4d2d-e5ed-e98addf94251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125000,)\n",
            "Train data: 125000 captions, 125000 images\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([112500, 1536]), torch.Size([112500, 1024]), 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 4. Data Augmentation\n",
        "# 5. Zero Shot Stitching\n",
        "# 6. Triplet Loss / Improve InfoNCE Loss / bidirectional / SimCLR / MoCo\n",
        "# 7. Autoencoder\n",
        "# Configuration\n",
        "EPOCHS = 60\n",
        "BATCH_SIZE = 512\n",
        "LR = 0.001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load data\n",
        "train_data = load_data(\"drive/MyDrive/data/train/train.npz\")\n",
        "X, y, label = prepare_train_data(train_data)\n",
        "DATASET_SIZE = len(X)\n",
        "# Split train/val\n",
        "# This is done only to measure generalization capabilities, you don't have to\n",
        "# use a validation set (though we encourage this)\n",
        "n_train = int(0.9 * len(X))\n",
        "TRAIN_SPLIT = torch.zeros(len(X), dtype=torch.bool)\n",
        "TRAIN_SPLIT[:n_train] = 1\n",
        "X_train, X_val = X[TRAIN_SPLIT], X[~TRAIN_SPLIT]\n",
        "y_train, y_val = y[TRAIN_SPLIT], y[~TRAIN_SPLIT]\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "y_train.shape, X_train.shape, train_loader.batch_size, val_loader.batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e4bed17",
      "metadata": {
        "id": "2e4bed17"
      },
      "source": [
        "### Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45828c5",
      "metadata": {
        "id": "f45828c5",
        "outputId": "b8b52313-0576-4181-d85e-91400b48ce00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46d6b64",
      "metadata": {
        "id": "b46d6b64"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def objective_extended(arch, trial, train_dataloader, val_dataloader, device, MODEL_PATH_BASE):\n",
        "\n",
        "    # --- Common hyperparameters ---\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    #lr = trial.suggest_loguniform(\"lr\", 5e-4, 1e-2)\n",
        "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3)\n",
        "\n",
        "    # --- New hyperparameters ---\n",
        "    temperature = trial.suggest_float(\"temperature\", 0.01, 0.2)\n",
        "    queue_size = trial.suggest_categorical(\"queue_size\", [2048, 4098, 8196])\n",
        "    #w_infonce = trial.suggest_float(\"w_infonce\", 0.6, 0.8)\n",
        "    #w_cos = trial.suggest_float(\"w_cos\", 0.4, 1.0)\n",
        "    #w_mse = trial.suggest_float(\"w_mse\", 1.0 - w_cos, 1.0)\n",
        "    procrustes_subset = 10000\n",
        "\n",
        "    # --- Architecture-specific hyperparameters ---\n",
        "    if arch in [\"MLP\", \"ResidualMLP\"]:\n",
        "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [1024, 2048, 4096])\n",
        "        num_layers = trial.suggest_int(\"num_layers\", 2, 6)\n",
        "        if arch == \"MLP\":\n",
        "            model = LatentSpaceTranslator(\n",
        "                text_dim=1024, img_dim=1536, hidden_dim=hidden_dim,\n",
        "                num_layers=num_layers, dropout=dropout\n",
        "            ).to(device)\n",
        "        else:\n",
        "            model = ResidualMLPTranslator(\n",
        "                text_dim=1024, img_dim=1536, hidden_dim=hidden_dim,\n",
        "                num_layers=num_layers, dropout=dropout\n",
        "            ).to(device)\n",
        "    elif arch == \"Transformer\":\n",
        "        n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
        "        n_heads = trial.suggest_categorical(\"n_heads\", [4, 8, 12])\n",
        "        dim_feedforward = trial.suggest_categorical(\"dim_feedforward\", [1024, 2048, 4096])\n",
        "        model = TransformerTranslator(\n",
        "            text_dim=1024, img_dim=1536,\n",
        "            n_heads=n_heads, n_layers=n_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout\n",
        "        ).to(device)\n",
        "\n",
        "\n",
        "    # --- Apply Procrustes initialization ---\n",
        "    if procrustes_subset > 0:\n",
        "        # Get subset from train_loader\n",
        "        text_list, img_list = [], []\n",
        "        for i, (X, y) in enumerate(train_loader):\n",
        "            text_list.append(X.cpu())\n",
        "            img_list.append(y.cpu())\n",
        "            if sum(t.shape[0] for t in text_list) >= procrustes_subset:\n",
        "                break\n",
        "        text_sample = torch.cat(text_list, dim=0)[:procrustes_subset]\n",
        "        img_sample = torch.cat(img_list, dim=0)[:procrustes_subset]\n",
        "        model = apply_procrustes_init_to_final(model, text_sample, img_sample)\n",
        "\n",
        "    criterion = QueueInfoNCELoss(dim=1536, temperature=temperature, queue_size=queue_size).to(device)\n",
        "    # --- Training loop (short run) ---\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6, weight_decay=weight_decay)\n",
        "    model.train()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    for epoch in range(5):  # short training\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_batch)\n",
        "\n",
        "            # Weighted combination of losses\n",
        "            loss = criterion(pred, y_batch)\n",
        "            #loss += w_infonce * info_nce_loss(pred, y_batch, temperature=temperature)\n",
        "            loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "            loss += 0.1 * (1 - F.cosine_similarity(pred, y_batch).mean())\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              keys = F.normalize(y_batch, dim=1).detach()   # image embeddings (targets) as keys\n",
        "              # put them into the queue\n",
        "              criterion._enqueue(keys)\n",
        "\n",
        "    # --- Evaluate on validation ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            pred = model(X_batch)\n",
        "            # Use combined loss for evaluation\n",
        "            loss = criterion(pred, y_batch)\n",
        "            #loss += w_infonce * info_nce_loss(pred, y_batch, temperature=temperature)\n",
        "            loss += 0.1 * F.mse_loss(pred, y_batch)\n",
        "            loss += 0.1 * (1 - F.cosine_similarity(pred, y_batch).mean())\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            keys = F.normalize(y_batch, dim=1).detach()\n",
        "            criterion._enqueue(keys)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "def run_optuna_extended(arch, train_dataloader, val_dataloader, device, MODEL_PATH_BASE, n_trials=20):\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective_extended(arch, trial, train_dataloader, val_dataloader, device, MODEL_PATH_BASE),\n",
        "                   n_trials=n_trials)\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "    print(f\"Val loss: {trial.value}\")\n",
        "    print(\"Best hyperparameters:\")\n",
        "    for key, value in trial.params.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    return trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc8d430c",
      "metadata": {
        "id": "dc8d430c",
        "outputId": "6b8e84dc-62a6-4a86-cab2-2a7c6521c10c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:52:30,336] A new study created in memory with name: no-name-1887fc2e-5326-4f35-bfbf-119d2c393839\n",
            "/tmp/ipython-input-986257601.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:53:25,688] Trial 0 finished with value: 5.602142181396484 and parameters: {'dropout': 0.13988157969633042, 'weight_decay': 0.00027218587622798826, 'temperature': 0.13801502246204728, 'queue_size': 2048, 'hidden_dim': 2048, 'num_layers': 4}. Best is trial 0 with value: 5.602142181396484.\n",
            "/tmp/ipython-input-986257601.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:54:15,461] Trial 1 finished with value: 4.726018333435059 and parameters: {'dropout': 0.3865957275463121, 'weight_decay': 4.516262051873357e-05, 'temperature': 0.04068788951599312, 'queue_size': 8196, 'hidden_dim': 2048, 'num_layers': 4}. Best is trial 1 with value: 4.726018333435059.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:54:56,666] Trial 2 finished with value: 7.614602088928223 and parameters: {'dropout': 0.48380258719225266, 'weight_decay': 0.00017845500807216883, 'temperature': 0.19932745354845804, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 2}. Best is trial 1 with value: 4.726018333435059.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:55:37,145] Trial 3 finished with value: 6.784299507141113 and parameters: {'dropout': 0.27202450279544943, 'weight_decay': 0.00010501422388546119, 'temperature': 0.12064241323284465, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 2}. Best is trial 1 with value: 4.726018333435059.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:56:11,194] Trial 4 finished with value: 5.3366352081298825 and parameters: {'dropout': 0.34184670243690807, 'weight_decay': 0.0007147548987615996, 'temperature': 0.08014972812542434, 'queue_size': 4098, 'hidden_dim': 2048, 'num_layers': 2}. Best is trial 1 with value: 4.726018333435059.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:56:52,147] Trial 5 finished with value: 3.965814399719238 and parameters: {'dropout': 0.4113143004063229, 'weight_decay': 0.0007865448700760865, 'temperature': 0.021212471129135442, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 2}. Best is trial 5 with value: 3.965814399719238.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:57:31,258] Trial 6 finished with value: 5.469992389678955 and parameters: {'dropout': 0.21379619184848475, 'weight_decay': 0.00024088626197937588, 'temperature': 0.12266329630528469, 'queue_size': 2048, 'hidden_dim': 1024, 'num_layers': 4}. Best is trial 5 with value: 3.965814399719238.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:58:28,785] Trial 7 finished with value: 6.089898719787597 and parameters: {'dropout': 0.3863040584393308, 'weight_decay': 1.8422779288746886e-05, 'temperature': 0.12561740963649964, 'queue_size': 4098, 'hidden_dim': 4096, 'num_layers': 3}. Best is trial 5 with value: 3.965814399719238.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:59:08,159] Trial 8 finished with value: 5.987352638244629 and parameters: {'dropout': 0.374334748413928, 'weight_decay': 3.2048298662422764e-05, 'temperature': 0.17018875031633235, 'queue_size': 2048, 'hidden_dim': 2048, 'num_layers': 3}. Best is trial 5 with value: 3.965814399719238.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 13:59:54,305] Trial 9 finished with value: 6.702498397827148 and parameters: {'dropout': 0.4337479263956773, 'weight_decay': 4.7996117071165214e-05, 'temperature': 0.15226402216064075, 'queue_size': 4098, 'hidden_dim': 1024, 'num_layers': 6}. Best is trial 5 with value: 3.965814399719238.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:02:01,927] Trial 10 finished with value: 3.900206651687622 and parameters: {'dropout': 0.49280063776204486, 'weight_decay': 0.0007663149199028488, 'temperature': 0.014929811555371139, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 6}. Best is trial 10 with value: 3.900206651687622.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:04:10,013] Trial 11 finished with value: 4.534354419708252 and parameters: {'dropout': 0.499197301753956, 'weight_decay': 0.0008274919706351165, 'temperature': 0.03109027514348669, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 6}. Best is trial 10 with value: 3.900206651687622.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:05:55,592] Trial 12 finished with value: 3.805408296585083 and parameters: {'dropout': 0.438221921899624, 'weight_decay': 0.00047048653635823473, 'temperature': 0.01215654889591665, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 5}. Best is trial 12 with value: 3.805408296585083.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:07:41,099] Trial 13 finished with value: 5.523218498229981 and parameters: {'dropout': 0.45293567927028167, 'weight_decay': 0.00045427813716587, 'temperature': 0.06691178961745486, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 5}. Best is trial 12 with value: 3.805408296585083.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:09:26,671] Trial 14 finished with value: 3.833653383255005 and parameters: {'dropout': 0.3107580525115931, 'weight_decay': 0.0004121402924828538, 'temperature': 0.01228647728601838, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 5}. Best is trial 12 with value: 3.805408296585083.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:11:12,250] Trial 15 finished with value: 5.117255363464356 and parameters: {'dropout': 0.29510678970819215, 'weight_decay': 0.0004026173322429398, 'temperature': 0.05623813815942236, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 5}. Best is trial 12 with value: 3.805408296585083.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:11:57,187] Trial 16 finished with value: 6.375839900970459 and parameters: {'dropout': 0.22499402453529804, 'weight_decay': 0.0001096497513441359, 'temperature': 0.09480575339858055, 'queue_size': 8196, 'hidden_dim': 1024, 'num_layers': 5}. Best is trial 12 with value: 3.805408296585083.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:13:42,910] Trial 17 finished with value: 4.8941993904113765 and parameters: {'dropout': 0.331230372755109, 'weight_decay': 0.00039995637168569386, 'temperature': 0.04946211437221372, 'queue_size': 8196, 'hidden_dim': 4096, 'num_layers': 5}. Best is trial 12 with value: 3.805408296585083.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:15:21,660] Trial 18 finished with value: 2.704795560836792 and parameters: {'dropout': 0.121809429679504, 'weight_decay': 0.00016391957513145087, 'temperature': 0.013078017610847755, 'queue_size': 2048, 'hidden_dim': 4096, 'num_layers': 5}. Best is trial 18 with value: 2.704795560836792.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-10 14:15:56,980] Trial 19 finished with value: 4.644894561767578 and parameters: {'dropout': 0.10256018087464411, 'weight_decay': 0.0001557587152029654, 'temperature': 0.08040142060783084, 'queue_size': 2048, 'hidden_dim': 1024, 'num_layers': 3}. Best is trial 18 with value: 2.704795560836792.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "Val loss: 2.704795560836792\n",
            "Best hyperparameters:\n",
            "  dropout: 0.121809429679504\n",
            "  weight_decay: 0.00016391957513145087\n",
            "  temperature: 0.013078017610847755\n",
            "  queue_size: 2048\n",
            "  hidden_dim: 4096\n",
            "  num_layers: 5\n"
          ]
        }
      ],
      "source": [
        "archs = ['MLP', 'ResidualMLP', 'Transformer']\n",
        "choosen_arch = archs[0]\n",
        "best_params = run_optuna_extended(\n",
        "    arch = choosen_arch,\n",
        "    train_dataloader=train_loader,\n",
        "    val_dataloader=val_loader,\n",
        "    device=DEVICE,\n",
        "    MODEL_PATH_BASE=\"models/translator_optuna\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e38bcc",
      "metadata": {
        "id": "98e38bcc"
      },
      "source": [
        "### Training and Submission File Creation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if choosen_arch == 'Transformer':\n",
        "    model = TransformerTranslator(\n",
        "        text_dim=1024,\n",
        "        img_dim=1536,\n",
        "        n_heads = best_params['n_heads'],\n",
        "        n_layers=best_params['n_layers'],\n",
        "        dim_feedforward=best_params['dim_feedforward'],\n",
        "        dropout=best_params['dropout']\n",
        "    ).to(DEVICE)\n",
        "    MODEL_PATH = \"drive/MyDrive/data//models/transformer.pth\"\n",
        "\n",
        "elif choosen_arch == 'MLP':\n",
        "    model = LatentSpaceTranslator(\n",
        "    text_dim=1024,\n",
        "    img_dim=1536,\n",
        "    hidden_dim=best_params[\"hidden_dim\"],\n",
        "    num_layers=best_params[\"num_layers\"],\n",
        "    dropout=best_params[\"dropout\"]).to(DEVICE)\n",
        "    MODEL_PATH = \"drive/MyDrive/data/models/latent_space.pth\"\n",
        "\n",
        "else:\n",
        "    model = ResidualMLPTranslator(\n",
        "    text_dim=1024,\n",
        "    img_dim=1536,\n",
        "    hidden_dim=best_params[\"hidden_dim\"],\n",
        "    num_layers=best_params[\"num_layers\"],\n",
        "    dropout=best_params[\"dropout\"]).to(DEVICE)\n",
        "    MODEL_PATH = \"drive/MyDrive/data/models/residual.pth\""
      ],
      "metadata": {
        "id": "p0_hDfyGIngh"
      },
      "id": "p0_hDfyGIngh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204d7a49",
      "metadata": {
        "id": "204d7a49",
        "outputId": "16580910-8f8d-4967-8ee6-e91d5894f77f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Parameters: 62,447,616\n",
            "\n",
            "3. Training...\n",
            "Computing Procrustes initialization...\n",
            "torch.Size([1536, 1024]) torch.Size([1536, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/60: 100%|██████████| 220/220 [00:19<00:00, 11.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 4.025310, Val Loss = 3.654469\n",
            "  ✓ Saved best model (val_loss=3.654469)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/60: 100%|██████████| 220/220 [00:21<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 3.541855, Val Loss = 3.424860\n",
            "  ✓ Saved best model (val_loss=3.424860)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/60: 100%|██████████| 220/220 [00:21<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 3.305816, Val Loss = 3.298638\n",
            "  ✓ Saved best model (val_loss=3.298638)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/60: 100%|██████████| 220/220 [00:21<00:00, 10.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 3.158785, Val Loss = 3.219335\n",
            "  ✓ Saved best model (val_loss=3.219335)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/60: 100%|██████████| 220/220 [00:21<00:00, 10.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 3.048219, Val Loss = 3.158065\n",
            "  ✓ Saved best model (val_loss=3.158065)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/60: 100%|██████████| 220/220 [00:21<00:00, 10.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss = 2.963305, Val Loss = 3.109669\n",
            "  ✓ Saved best model (val_loss=3.109669)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/60: 100%|██████████| 220/220 [00:21<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss = 2.895276, Val Loss = 3.071921\n",
            "  ✓ Saved best model (val_loss=3.071921)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/60: 100%|██████████| 220/220 [00:21<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss = 2.829851, Val Loss = 3.039158\n",
            "  ✓ Saved best model (val_loss=3.039158)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/60: 100%|██████████| 220/220 [00:21<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss = 2.777101, Val Loss = 3.007188\n",
            "  ✓ Saved best model (val_loss=3.007188)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/60: 100%|██████████| 220/220 [00:21<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 2.728199, Val Loss = 2.975641\n",
            "  ✓ Saved best model (val_loss=2.975641)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/60: 100%|██████████| 220/220 [00:20<00:00, 10.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss = 2.679994, Val Loss = 2.952357\n",
            "  ✓ Saved best model (val_loss=2.952357)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/60: 100%|██████████| 220/220 [00:21<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss = 2.636763, Val Loss = 2.932172\n",
            "  ✓ Saved best model (val_loss=2.932172)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/60: 100%|██████████| 220/220 [00:20<00:00, 10.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss = 2.594970, Val Loss = 2.913260\n",
            "  ✓ Saved best model (val_loss=2.913260)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/60: 100%|██████████| 220/220 [00:21<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss = 2.559976, Val Loss = 2.892028\n",
            "  ✓ Saved best model (val_loss=2.892028)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/60: 100%|██████████| 220/220 [00:21<00:00, 10.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss = 2.526430, Val Loss = 2.879083\n",
            "  ✓ Saved best model (val_loss=2.879083)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/60: 100%|██████████| 220/220 [00:21<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss = 2.492939, Val Loss = 2.857621\n",
            "  ✓ Saved best model (val_loss=2.857621)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/60: 100%|██████████| 220/220 [00:21<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Loss = 2.458873, Val Loss = 2.846168\n",
            "  ✓ Saved best model (val_loss=2.846168)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/60: 100%|██████████| 220/220 [00:21<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss = 2.428234, Val Loss = 2.835800\n",
            "  ✓ Saved best model (val_loss=2.835800)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/60: 100%|██████████| 220/220 [00:21<00:00, 10.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss = 2.400388, Val Loss = 2.823987\n",
            "  ✓ Saved best model (val_loss=2.823987)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/60: 100%|██████████| 220/220 [00:21<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss = 2.372151, Val Loss = 2.808579\n",
            "  ✓ Saved best model (val_loss=2.808579)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/60: 100%|██████████| 220/220 [00:21<00:00, 10.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Loss = 2.343073, Val Loss = 2.800201\n",
            "  ✓ Saved best model (val_loss=2.800201)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/60: 100%|██████████| 220/220 [00:20<00:00, 10.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Loss = 2.321756, Val Loss = 2.788595\n",
            "  ✓ Saved best model (val_loss=2.788595)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/60: 100%|██████████| 220/220 [00:20<00:00, 10.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Train Loss = 2.292934, Val Loss = 2.785415\n",
            "  ✓ Saved best model (val_loss=2.785415)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/60: 100%|██████████| 220/220 [00:21<00:00, 10.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Train Loss = 2.269086, Val Loss = 2.773109\n",
            "  ✓ Saved best model (val_loss=2.773109)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/60: 100%|██████████| 220/220 [00:20<00:00, 10.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Train Loss = 2.243230, Val Loss = 2.760132\n",
            "  ✓ Saved best model (val_loss=2.760132)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/60: 100%|██████████| 220/220 [00:19<00:00, 11.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Train Loss = 2.221591, Val Loss = 2.752860\n",
            "  ✓ Saved best model (val_loss=2.752860)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/60: 100%|██████████| 220/220 [00:20<00:00, 10.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Train Loss = 2.198233, Val Loss = 2.745769\n",
            "  ✓ Saved best model (val_loss=2.745769)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/60: 100%|██████████| 220/220 [00:19<00:00, 11.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Train Loss = 2.181579, Val Loss = 2.740107\n",
            "  ✓ Saved best model (val_loss=2.740107)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/60: 100%|██████████| 220/220 [00:19<00:00, 11.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Train Loss = 2.153477, Val Loss = 2.735236\n",
            "  ✓ Saved best model (val_loss=2.735236)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/60: 100%|██████████| 220/220 [00:21<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Train Loss = 2.133416, Val Loss = 2.725562\n",
            "  ✓ Saved best model (val_loss=2.725562)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/60: 100%|██████████| 220/220 [00:19<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Train Loss = 2.116151, Val Loss = 2.720297\n",
            "  ✓ Saved best model (val_loss=2.720297)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/60: 100%|██████████| 220/220 [00:19<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Train Loss = 2.095415, Val Loss = 2.714192\n",
            "  ✓ Saved best model (val_loss=2.714192)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/60: 100%|██████████| 220/220 [00:19<00:00, 11.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Train Loss = 2.076264, Val Loss = 2.714017\n",
            "  ✓ Saved best model (val_loss=2.714017)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/60: 100%|██████████| 220/220 [00:19<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Train Loss = 2.058806, Val Loss = 2.704292\n",
            "  ✓ Saved best model (val_loss=2.704292)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/60: 100%|██████████| 220/220 [00:20<00:00, 10.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Train Loss = 2.038321, Val Loss = 2.701115\n",
            "  ✓ Saved best model (val_loss=2.701115)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/60: 100%|██████████| 220/220 [00:19<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Train Loss = 2.023141, Val Loss = 2.696890\n",
            "  ✓ Saved best model (val_loss=2.696890)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/60: 100%|██████████| 220/220 [00:19<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Train Loss = 2.003083, Val Loss = 2.692477\n",
            "  ✓ Saved best model (val_loss=2.692477)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/60: 100%|██████████| 220/220 [00:19<00:00, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Train Loss = 1.984387, Val Loss = 2.689556\n",
            "  ✓ Saved best model (val_loss=2.689556)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/60: 100%|██████████| 220/220 [00:19<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Train Loss = 1.966116, Val Loss = 2.687265\n",
            "  ✓ Saved best model (val_loss=2.687265)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/60: 100%|██████████| 220/220 [00:19<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Train Loss = 1.950913, Val Loss = 2.682913\n",
            "  ✓ Saved best model (val_loss=2.682913)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/60: 100%|██████████| 220/220 [00:20<00:00, 10.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Train Loss = 1.935162, Val Loss = 2.675518\n",
            "  ✓ Saved best model (val_loss=2.675518)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/60: 100%|██████████| 220/220 [00:19<00:00, 11.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Train Loss = 1.915317, Val Loss = 2.673427\n",
            "  ✓ Saved best model (val_loss=2.673427)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/60: 100%|██████████| 220/220 [00:19<00:00, 11.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Train Loss = 1.900424, Val Loss = 2.668164\n",
            "  ✓ Saved best model (val_loss=2.668164)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/60: 100%|██████████| 220/220 [00:19<00:00, 11.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Train Loss = 1.883651, Val Loss = 2.664990\n",
            "  ✓ Saved best model (val_loss=2.664990)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/60: 100%|██████████| 220/220 [00:19<00:00, 11.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Train Loss = 1.870137, Val Loss = 2.661307\n",
            "  ✓ Saved best model (val_loss=2.661307)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/60: 100%|██████████| 220/220 [00:19<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: Train Loss = 1.855048, Val Loss = 2.662014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/60: 100%|██████████| 220/220 [00:19<00:00, 11.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: Train Loss = 1.839549, Val Loss = 2.659120\n",
            "  ✓ Saved best model (val_loss=2.659120)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/60: 100%|██████████| 220/220 [00:19<00:00, 11.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: Train Loss = 1.821775, Val Loss = 2.654799\n",
            "  ✓ Saved best model (val_loss=2.654799)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/60: 100%|██████████| 220/220 [00:19<00:00, 11.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: Train Loss = 1.809910, Val Loss = 2.654324\n",
            "  ✓ Saved best model (val_loss=2.654324)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/60: 100%|██████████| 220/220 [00:19<00:00, 11.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50: Train Loss = 1.793190, Val Loss = 2.649188\n",
            "  ✓ Saved best model (val_loss=2.649188)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/60: 100%|██████████| 220/220 [00:19<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51: Train Loss = 1.782620, Val Loss = 2.647235\n",
            "  ✓ Saved best model (val_loss=2.647235)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/60: 100%|██████████| 220/220 [00:19<00:00, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52: Train Loss = 1.767249, Val Loss = 2.649145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/60: 100%|██████████| 220/220 [00:20<00:00, 10.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53: Train Loss = 1.754129, Val Loss = 2.644963\n",
            "  ✓ Saved best model (val_loss=2.644963)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/60: 100%|██████████| 220/220 [00:19<00:00, 11.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54: Train Loss = 1.738909, Val Loss = 2.645812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/60: 100%|██████████| 220/220 [00:19<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55: Train Loss = 1.724115, Val Loss = 2.648268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/60: 100%|██████████| 220/220 [00:19<00:00, 11.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56: Train Loss = 1.712313, Val Loss = 2.636846\n",
            "  ✓ Saved best model (val_loss=2.636846)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/60: 100%|██████████| 220/220 [00:19<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57: Train Loss = 1.699573, Val Loss = 2.641919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/60: 100%|██████████| 220/220 [00:19<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58: Train Loss = 1.687620, Val Loss = 2.634441\n",
            "  ✓ Saved best model (val_loss=2.634441)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/60: 100%|██████████| 220/220 [00:21<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59: Train Loss = 1.674146, Val Loss = 2.639941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/60: 100%|██████████| 220/220 [00:20<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60: Train Loss = 1.659629, Val Loss = 2.634055\n",
            "  ✓ Saved best model (val_loss=2.634055)\n"
          ]
        }
      ],
      "source": [
        "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train\n",
        "print(\"\\n3. Training...\")\n",
        "model = training(model,\n",
        "                 train_loader,\n",
        "                 val_loader,\n",
        "                 DEVICE,\n",
        "                 EPOCHS,\n",
        "                 1e-6,\n",
        "                 MODEL_PATH,\n",
        "                 True,\n",
        "                 10000,\n",
        "                 best_params[\"temperature\"],\n",
        "                 best_params[\"queue_size\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff97f7b",
      "metadata": {
        "id": "cff97f7b",
        "outputId": "ad67278c-4060-4fae-cc3c-bba33dffa160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating submission file...\n",
            "✓ Saved submission to MLP_submission.csv\n",
            "Model saved to: drive/MyDrive/data/models/latent_space.pth\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "test_data = load_data(\"drive/MyDrive/data/test/test.clean.npz\")\n",
        "\n",
        "test_embds = test_data['captions/embeddings']\n",
        "test_embds = torch.from_numpy(test_embds).float()\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_embds = model(test_embds.to(DEVICE)).cpu()\n",
        "\n",
        "submission = generate_submission(test_data['captions/ids'], pred_embds, f'{choosen_arch}_submission.csv')\n",
        "print(f\"Model saved to: {MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KKSa0Jl55hd"
      },
      "id": "_KKSa0Jl55hd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}